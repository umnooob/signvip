seed: 42
weight_dtype: fp32
stage_init: True
distill_loss_weight: 1

modules:
  vae: ./pretrain_models/sd-vae-ft-mse
  unet_2d: ./pretrain_models/stable-diffusion-v1-5/unet/
  text_encoder: ./pretrain_models/stable-diffusion-v1-5/text_encoder/
  tokenizer: ./pretrain_models/stable-diffusion-v1-5/tokenizer/
  scheduler: ./pretrain_models/stable-diffusion-v1-5/scheduler/
  apperance_encoder: ./workspace/stage_1_multicond_RWTH/xx/best/appearance_encoder
  condition_encoder: ./workspace/stage_1_multicond_RWTH/xx/best/condition_encoder/model.bin
  condition_encoder_motion: ./workspace/stage_2_RWTH/xx/best/condition_encoder/model.bin
  vq_model: 
  mm: ./workspace/stage_2_RWTH/xx/best/unet/model.bin
  unet: 
  condition_encoder_kwargs:
    use_vq: true
    vq_kwargs:
      n_e: 625
      vq_type: FSQ
      fsq_levels: [5, 5, 5, 5]
      quantizer_channels: 4
      ch_mult:
        - 1
        - 2
        - 4
        - 8
      input_size:
        - 34
        - 28

  unet_additional_kwargs:
    use_motion_module: true
    motion_module_resolutions:
    - 1
    - 2
    - 4
    - 8
    unet_use_cross_frame_attention: false
    unet_use_temporal_attention: false
    motion_module_type: Vanilla
    motion_module_kwargs:
      num_attention_heads: 8
      num_transformer_block: 1
      attention_block_types:
      - Temporal_Self
      - Temporal_Self
      temporal_position_encoding: true
      temporal_position_encoding_max_len: 32
      temporal_attention_dim_div: 1
      zero_initialize: true

grad:
  vae: False
  unet_2d: False
  appearance_encoder: False
  text_encoder: False
  condition_encoder: False

trainable_modules:
  - vq.
gradient_checkpointing: False

solver:
  max_train_steps: 30000
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  optimizer:
    use_8bit_adam: True
    learning_rate: 1e-4
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_weight_decay: 1.0e-6
    adam_epsilon: 1.0e-8
  lr_scheduler:
    name: "cosine"
    lr_warmup_steps: 500
    num_cycles: 0.5

dataset:
  frame_size: [272,224]
  frame_scale: [ 1.0, 1.0 ]
  frame_ratio: [ 0.9, 1.0 ]
  roots:
    - "/deepo_data/signvipworkspace/datasets/RWTH-T"
  sk_roots:
    - "/deepo_data/signvipworkspace/datasets/RWTH-TSK"
  hamer_roots:
    - "/deepo_data/signvipworkspace/datasets/RWTH-TSmplerx"
  meta_paths:
    - "/deepo_data/signvipworkspace/datasets/RWTH-T/train_processed_videos.json"
  sample_rate: 2
  num_frames: 4
  ref_margin: 1
  uncond_ratio: 1
  mask_ratio: 0
  mask_thershold: 0.85
  skip_ratio: 0
  sk_mask_ratio: 0
  hamer_mask_ratio: 0
  both_mask_ratio: 0

dataloader:
  batch_size: 32
  num_workers: 4

noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start: 0.00085
  beta_end: 0.012
  beta_schedule: "scaled_linear"
  steps_offset: 1
  clip_sample: false

resume_from_checkpoint: 
checkpointing_steps: 2500
valid_steps: 2500
max_ckpt: 1
max_model: 1

noise_offset: 0
clip_skip: 1
snr_gamma: 0

max_visible_frames: 6

validation_data:
  meta_paths:
    - "/deepo_data/signvipworkspace/datasets/RWTH-T/dev_processed_videos.json"
  prompt: ""
  num_inference_steps: 20
  guidance_scale: 3.5
